{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: How to Train Your Model\n",
    "\n",
    "In Jupyter Notebook 2: Matrices, we saw that images are stored digitally as multidimensional arrays. Another name for a multidimensional array is a *tensor*. This project will introduce you to TensorFlow, a machine learning programming library created by Google and used by many companies for creating and training models. It’s named after tensors, which are the primary object of coding with TensorFlow.\n",
    "\n",
    "Let's check to see if you have Tensorflow installed, and install it if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(\"\\nTensorflow is installed.\")\n",
    "except ImportError as e:\n",
    "    print(\"Tensorflow not installed, please install it using 'pip install tensorflow.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell if you need to install tensorflow.\n",
    "pip install tensorflow # install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 1**\n",
    "It’s important to appreciate the computational efficiency of programming with tensors. Let’s work through an example that illustrates this. In the two code cells below, compute the element-wise product of two vectors. I provided you with the code for using a TensorFlow command. In the code cell below that, perform the same computation using a for loop and the multiplication operation `*`. *Hint:* You should use the command `product = np.zeros(size)` to initialize a vector for your for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "size = (50000,)\n",
    "u = tf.random.uniform(size)\n",
    "v = tf.random.uniform(size)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "tf.math.multiply(u, v)\n",
    "end_time = time.perf_counter()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow\n",
    "\n",
    "Many of the array operations and functions in Tensorflow should feel familiar to NumPy, however some basic operations require us to use TensorFlow functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 2**\n",
    "\n",
    "Use the commands `tf.constant`, `tf.matmul`, `tf.scalar_mul`, and `tf.add` to define two $2\\times 2$ matrices $A$ and $B$ and compute $AB+3B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 3**\n",
    "\n",
    "Print the entry in the first row and second column of the tensor $A$ you defined in the previous problem. Describe the output in a sentence in a comment or Markdown cell below your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it's convenient to convert tensor objects to NumPy arrays and vice versa. Let's see how this is done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A.numpy()) # convert tensor to numpy array\n",
    "\n",
    "A_r1 = A.numpy()[0] # first row of A as numpy array\n",
    "A_r1 = tf.constant(A_r1) # convert numpy array to tensor\n",
    "\n",
    "print(A_r1) # convert numpy array to tensor \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 4**\n",
    "\n",
    "Print out the tensor $B$ as a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset\n",
    "\n",
    "Now let's load the MNIST dataset, which contains 70,000 samples of handwritten digits. This data is conveniently included in TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data() # load dataset and split into training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 5**\n",
    "\n",
    "Display the first image. What is the image? Use Python and the `train_labels` to print a message stating the digit in the image.  *Tip: Refer to Jupyter Notebook 2 if you need to review how to display an image.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data\n",
    "\n",
    "Computer processors comprise many transistors, which are essentially on/off switches. When we say computers work in binary, really we are referring to these transistors. For the most part, in all of our computations we will store float values as `float32`, which means each number is represented by `32` transistors (or bits if we want to refer to the binary representation). \n",
    "\n",
    "Computers are generally more efficient working with float values between 0 and 1. Let's explore why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "### **Problem 6**\n",
    "\n",
    "1. By either computing yourself, or doing an internet search, determine how many floating point numbers are there in a 32-bit system. What about a normalized 32-bit system?\n",
    "\n",
    "2. By either computing yourself, or doing an internet search, determine the decimal precision of a 32-bit floating point number and a 32-bit floating point number in the range $0$ to $1$.\n",
    "\n",
    "Write your answers in the Markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "### **Problem 7**\n",
    "\n",
    "Normalize the training and testing datasets and use the `tf.reshape` command to reshape the images to be arrays of size `(784,)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 8**\n",
    "\n",
    "As we discussed in class, we need to convert the labels to categorical data. Fortunately, there is a command for this: `tf.keras.utils.to_categorical`. \n",
    "\n",
    "Convert the training and testing labels to categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing and Training Our Model\n",
    "\n",
    "Defining a feedforward neural network using Tensorflow takes just a few lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(784,)),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should specify our loss function and *optimizer*. The optimizer is our method for training--we'll discuss more methods in the future. For now, let's use stochastic gradient descent with `learning_rate=0.01`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = tf.keras.losses.MSE\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy']) # initialize model weights and compile model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 9**\n",
    "\n",
    "Apply the model to the training data by running `model(train_images)`--define this as `pred_labels`. Then compute and print `loss_function(train_labels, pred_labels)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images,\n",
    "          train_labels, \n",
    "          epochs=5, \n",
    "          batch_size=32) # train model on training data for 5 epochs with batch size of 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 10**\n",
    "Complete the following tasks:\n",
    "\n",
    "1. Load the Fashion MNIST dataset using the command `tf.keras.datasets.fashion_mnist.load_data()`\n",
    "2. Display the first 5 images and print their labels.\n",
    "3. Prepare the training and testing data. That is, normalize and reshape the images and convert the labels to categorical data.\n",
    "4. Define and train a model with $784\\times 128\\times 64\\times 32\\times 10$ architecture with the ReLU activation function in every layer except the last. For the final layer, use softmax for the activation function. Use stochastic gradient descent to train the model and mean squared error for its loss function. Train until your model has at least $90\\%$ accuracy on the training data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
